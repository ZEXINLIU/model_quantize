{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d3cd2a",
   "metadata": {},
   "source": [
    "# 卷积层与批归一化层的融合推导\n",
    "\n",
    "当我们将卷积层（Conv）与批归一化层（BatchNorm, BN）融合时，BN 的参数会被合并到卷积层的权重和偏置中。以下是详细的推导过程。\n",
    "\n",
    "## 1. 卷积层输出\n",
    "\n",
    "设卷积层的权重和偏置为：\n",
    "\n",
    "- 权重：\\( W \\)\n",
    "- 偏置：\\( b \\)\n",
    "\n",
    "输入为 \\( x \\)，卷积层的输出为：\n",
    "\n",
    "$$\n",
    "y = W \\cdot x + b\n",
    "$$\n",
    "\n",
    "## 2. 批归一化层\n",
    "\n",
    "批归一化层的参数为：\n",
    "\n",
    "- 伽马：\\( \\gamma \\)\n",
    "- 贝塔：\\( \\beta \\)\n",
    "- 均值：\\( \\mu \\)\n",
    "- 方差：\\( \\sigma^2 \\)\n",
    "\n",
    "在批归一化中，输出为：\n",
    "\n",
    "$$\n",
    "\\text{BN}(y) = \\gamma \\left( \\frac{y - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\right) + \\beta\n",
    "$$\n",
    "\n",
    "其中，\\( \\epsilon \\) 是一个小的常数，防止除零错误。\n",
    "\n",
    "## 3. 将卷积输出代入批归一化\n",
    "\n",
    "将卷积输出 \\( y \\) 代入批归一化公式：\n",
    "\n",
    "$$\n",
    "\\text{BN}(y) = \\gamma \\left( \\frac{(W \\cdot x + b) - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\right) + \\beta\n",
    "$$\n",
    "\n",
    "## 4. 展开和整理\n",
    "\n",
    "展开公式后，可以得到：\n",
    "\n",
    "$$\n",
    "\\text{BN}(y) = \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}} (W \\cdot x + b) - \\frac{\\gamma \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta\n",
    "$$\n",
    "\n",
    "## 5. 定义新的卷积参数\n",
    "\n",
    "我们可以定义新的卷积层参数：\n",
    "\n",
    "- 新的权重：\n",
    "\n",
    "$$\n",
    "W' = \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}} W\n",
    "$$\n",
    "\n",
    "- 新的偏置：\n",
    "\n",
    "$$\n",
    "b' = \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}} b - \\frac{\\gamma \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta\n",
    "$$\n",
    "\n",
    "## 6. 完整的输出表达式\n",
    "\n",
    "融合后的输出可以表示为：\n",
    "\n",
    "$$\n",
    "\\text{FusedOutput}(x) = W' \\cdot x + b'\n",
    "$$\n",
    "\n",
    "## 结论\n",
    "\n",
    "通过上述推导，我们可以看到 `BatchNorm` 的参数已经成功融合到了卷积层的权重和偏置中。这种融合可以简化模型并提高推理性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cecf307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手动计算批次均值: tensor([-0.0680], grad_fn=<MeanBackward1>)\n",
      "手动计算批次方差: tensor([0.2569], grad_fn=<VarBackward0>)\n",
      "手动计算的运行均值: tensor([-0.0068], grad_fn=<AddBackward0>)\n",
      "手动计算的运行方差: tensor([0.9257], grad_fn=<AddBackward0>)\n",
      "评估模式下，计算的运行均值: tensor([-0.0068])\n",
      "评估模式下，计算的运行方差: tensor([0.9257])\n",
      "Outputs are equal: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建卷积和批归一化层\n",
    "conv = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1)\n",
    "bn = nn.BatchNorm2d(1)\n",
    "\n",
    "# 随机输入\n",
    "x = torch.randn(1, 1, 5, 5)\n",
    "\n",
    "# 原始的卷积和批归一化输出\n",
    "conv_output = conv(x)\n",
    "bn.train()  # 设置为训练模式，计算当前批次的均值和方差\n",
    "bn_output_train = bn(conv_output)\n",
    "\n",
    "manual_batch_mean = torch.mean(conv_output, dim=[0, 2, 3])\n",
    "# 注意训练模式下，当前batch的方差是无偏的\n",
    "manual_batch_var = torch.var(conv_output, dim=[0, 2, 3], unbiased=True)\n",
    "print(f\"手动计算批次均值: {manual_batch_mean}\")\n",
    "print(f\"手动计算批次方差: {manual_batch_var}\")\n",
    "\n",
    "# 假设初始的运行均值和方差\n",
    "init_running_mean = torch.zeros(1)  # 初始为0\n",
    "init_running_var = torch.ones(1)  # 初始为1\n",
    "\n",
    "# 设置 alpha\n",
    "alpha = 0.9  # 通常使用较小的值\n",
    "\n",
    "# 更新运行均值和方差\n",
    "manual_running_mean = alpha * init_running_mean + (1 - alpha) * manual_batch_mean\n",
    "manual_running_var = alpha * init_running_var + (1 - alpha) * manual_batch_var\n",
    "print(f\"手动计算的运行均值: {manual_running_mean}\")\n",
    "print(f\"手动计算的运行方差: {manual_running_var}\")\n",
    "\n",
    "# 切换到评估模式以使用运行均值和方差\n",
    "bn.eval()\n",
    "bn_output_eval = bn(conv_output)\n",
    "\n",
    "# 计算运行均值和方差\n",
    "running_mean = bn.running_mean\n",
    "# 测试时，当前\n",
    "running_var = bn.running_var\n",
    "print(f\"评估模式下，计算的运行均值: {running_mean}\")\n",
    "print(f\"评估模式下，计算的运行方差: {running_var}\")\n",
    "\n",
    "\n",
    "# 融合后的参数计算\n",
    "gamma = bn.weight\n",
    "beta = bn.bias\n",
    "mean = bn.running_mean\n",
    "var = bn.running_var\n",
    "epsilon = bn.eps\n",
    "\n",
    "# 计算融合后的参数\n",
    "weight_fused = (gamma / (var + epsilon).sqrt()) * conv.weight\n",
    "bias_fused = (gamma / (var + epsilon).sqrt()) * conv.bias - (gamma * mean / (var + epsilon).sqrt()) + beta\n",
    "\n",
    "# 计算融合后的输出\n",
    "fused_output = torch.nn.functional.conv2d(x, weight_fused, bias_fused, stride=1, padding=1)\n",
    "\n",
    "# 验证\n",
    "is_equal = torch.allclose(bn_output_eval, fused_output, atol=1e-6)\n",
    "print(f\"Outputs are equal: {is_equal}\")  # 应为 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bef61ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评估模式下，计算的运行均值: 0.13081976771354675\n",
      "评估模式下，计算的运行方差: 0.4471468925476074\n",
      "手动计算的滑动平均运行均值: 0.13081976771354675\n",
      "手动计算的滑动平均运行方差: 0.4471468925476074\n",
      "运行均值一致性: True\n",
      "运行方差一致性: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建卷积和批归一化层\n",
    "conv = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1)\n",
    "bn = nn.BatchNorm2d(1)\n",
    "\n",
    "# 假设初始的运行均值和方差\n",
    "init_running_mean = torch.zeros(1)  # 初始为0\n",
    "init_running_var = torch.ones(1)  # 初始为1\n",
    "\n",
    "# 设置 alpha\n",
    "alpha = 0.9  # 通常使用较小的值\n",
    "\n",
    "# 用于记录每个批次的均值和方差\n",
    "batch_means = []\n",
    "batch_vars = []\n",
    "\n",
    "# 输入数据：10个批次\n",
    "num_batches = 10\n",
    "batch_size = 16\n",
    "input_shape = (batch_size, 1, 5, 5)\n",
    "\n",
    "# 初始化运行均值和方差\n",
    "running_mean = init_running_mean.clone()\n",
    "running_var = init_running_var.clone()\n",
    "\n",
    "for i in range(num_batches):\n",
    "    # 生成随机输入\n",
    "    x = torch.randn(input_shape)\n",
    "    \n",
    "    # 训练模式下处理当前批次\n",
    "    conv_output = conv(x)\n",
    "    bn.train()\n",
    "    bn_output_train = bn(conv_output)\n",
    "\n",
    "    # 计算当前批次的均值和方差\n",
    "    batch_mean = torch.mean(conv_output, dim=[0, 2, 3])\n",
    "    # 注意这里当前batch的方差是基于无偏估计（若使用有偏估计，则手动与运行方差结果不一致）\n",
    "    # 但是训练模式下，running_var 是通过当前批次的有偏方差（使用 N 作为分母）进行更新的，这里矛盾？\n",
    "    batch_var = torch.var(conv_output, dim=[0, 2, 3], unbiased=True)\n",
    "\n",
    "    # 记录均值和方差\n",
    "    batch_means.append(batch_mean)\n",
    "    batch_vars.append(batch_var)\n",
    "\n",
    "    # 更新运行均值和方差\n",
    "    running_mean = alpha * running_mean + (1 - alpha) * batch_mean\n",
    "    running_var = alpha * running_var + (1 - alpha) * batch_var\n",
    "\n",
    "# 切换到评估模式\n",
    "bn.eval()\n",
    "# 最后一个批次的输出用于评估\n",
    "bn_output_eval = bn(conv_output)\n",
    "\n",
    "# 获取评估模式下的运行均值和方差\n",
    "eval_running_mean = bn.running_mean\n",
    "eval_running_var = bn.running_var\n",
    "\n",
    "# 手动计算滑动平均的运行均值和方差\n",
    "manual_running_mean = init_running_mean.clone()\n",
    "manual_running_var = init_running_var.clone()\n",
    "\n",
    "for mean, var in zip(batch_means, batch_vars):\n",
    "    manual_running_mean = alpha * manual_running_mean + (1 - alpha) * mean\n",
    "    manual_running_var = alpha * manual_running_var + (1 - alpha) * var\n",
    "\n",
    "# 输出结果\n",
    "print(f\"评估模式下，计算的运行均值: {eval_running_mean.item()}\")\n",
    "print(f\"评估模式下，计算的运行方差: {eval_running_var.item()}\")\n",
    "\n",
    "print(f\"手动计算的滑动平均运行均值: {manual_running_mean.item()}\")\n",
    "print(f\"手动计算的滑动平均运行方差: {manual_running_var.item()}\")\n",
    "\n",
    "# 比较结果\n",
    "mean_equal = torch.allclose(eval_running_mean, manual_running_mean)\n",
    "var_equal = torch.allclose(eval_running_var, manual_running_var)\n",
    "\n",
    "print(f\"运行均值一致性: {mean_equal}\")\n",
    "print(f\"运行方差一致性: {var_equal}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
